[{"title":"","date":"2019-02-20T03:06:17.552Z","path":"2019/02/20/Mysql主从/","text":"1docker cp mysql:/etc/mysql /etc/mysql 创建/etc/mysql/mysql_master、/etc/mysql/mysql_slave目录，将/etc/mysql中拷贝至这两个文件夹 修改/etc/mysql/mysql_master/my.cnf文件，添加以下配置内容 123[mysqld]log-bin=mysql-binserver-id=1 启动mysql_master 1docker run --name mysql_master -v /etc/mysql/mysql_master:/etc/mysql -p 3307:3306 -e MYSQL_ROOT_PASSWORD=123456 -d mysql 修改/etc/mysql/mysql_slave/my.cnf文件，添加以下配置内容 12[mysqld]server-id=2 启动mysql_slave 1docker run --name mysql_slave -v /etc/mysql/mysql_slave:/etc/mysql -p 3308:3306 -e MYSQL_ROOT_PASSWORD=123456 -d mysql 进入mysql_master 123docker exec -it mysql_master bashmysql -u root -p 在master节点创建一个用户slave，用于slave节点链接master节点时使用。 123CREATE USER 'slave'@'' IDENTIFIED WITH mysql_native_password BY '123456';GRANT REPLICATION SLAVE ON *.* TO 'slave'@''; 1SHOW MASTER STATUS; 进入mysql_slave，执行以下命令，其中MASTER_LOG_FILE、MASTER_LOG_POS值为MASTER STATUS;```显示值12 CHANGE MASTER TOMASTER_HOST=’192.168.244.137’,MASTER_USER=’slave’,MASTER_PORT=3307,MASTER_PASSWORD=’123456’,MASTER_LOG_FILE=’mysql-bin.000003’,MASTER_LOG_POS=409;12 start slave; show slave status\\G;```","tags":[]},{"title":"Redis内存淘汰策略","date":"2019-02-14T16:00:00.000Z","path":"2019/02/15/Redis内存淘汰策略/","text":"现在实际项目中用到redis的越来越多，今天心血来潮研究了下Redis内存的淘汰策略。 所谓内存淘汰策略，就是在往redis里面存储key时内存不足执行的策略。 首先使用Docker启动redis 1docker run -d -v /usr/local/etc/redis/redis.conf:/usr/local/etc/redis/redis.conf -p 6379:6379 --name redis redis redis-server /usr/local/etc/redis/redis.conf 需要在redis官网下载获取最新的redis.conf放在/usr/local/etc/redis/ 总共有8种策略，以下是redis.conf关于内存淘汰策略的原文介绍 123456789101112131415161718192021222324252627282930# MAXMEMORY POLICY: how Redis will select what to remove when maxmemory# is reached. You can select among five behaviors:## volatile-lru -&gt; Evict using approximated LRU among the keys with an expire set.# allkeys-lru -&gt; Evict any key using approximated LRU.# volatile-lfu -&gt; Evict using approximated LFU among the keys with an expire set.# allkeys-lfu -&gt; Evict any key using approximated LFU.# volatile-random -&gt; Remove a random key among the ones with an expire set.# allkeys-random -&gt; Remove a random key, any key.# volatile-ttl -&gt; Remove the key with the nearest expire time (minor TTL)# noeviction -&gt; Don't evict anything, just return an error on write operations.## LRU means Least Recently Used# LFU means Least Frequently Used## Both LRU, LFU and volatile-ttl are implemented using approximated# randomized algorithms.## Note: with any of the above policies, Redis will return an error on write# operations, when there are no suitable keys for eviction.## At the date of writing these commands are: set setnx setex append# incr decr rpush lpush rpushx lpushx linsert lset rpoplpush sadd# sinter sinterstore sunion sunionstore sdiff sdiffstore zadd zincrby# zunionstore zinterstore hset hsetnx hmset hincrby incrby decrby# getset mset msetnx exec sort## The default is:## maxmemory-policy noeviction 下面对各种策略进行测试 将redis最大内存调整为1m，修改redis.conf 1maxmemory 1048576 修改内存淘汰策略1maxmemory-policy noeviction 1、noevication，新写入操作报错。 测试代码 123456789101112131415161718@Testpublic void noevicationTest() &#123; //flush db redisTemplate.delete(redisTemplate.keys(\"*\")); //1k byte[] bytes = new byte[1024]; int i = 0; while (true) &#123; try &#123; redisTemplate.opsForValue().set(String.valueOf(i), bytes); System.out.println(i++); &#125; catch (Exception e) &#123; e.printStackTrace(); break; &#125; &#125;&#125; 在执行到i为145的时候抛出了异常，有点费解，value为1k，key顶多就几b，把redis最大内存改为10m，可以到7000多个，不知道还有什么占用了内存。 2、volatile-lru，使用LRU算法删除设置了expire的key 注：redis使用的是一种伪LRU算法，应该是出于性能考虑 LRU（Least recently used，最近最少使用）算法根据数据的历史访问记录来进行淘汰数据，其核心思想是“如果数据最近被访问过，那么将来被访问的几率也更高”。 测试代码 123456789101112131415161718@Testpublic void volatileTest() &#123; //flush db redisTemplate.delete(redisTemplate.keys(\"*\")); //1k byte[] bytes = new byte[1024]; int i = 0; for (; i &lt; 100; i++) &#123; redisTemplate.opsForValue().set(String.valueOf(i), bytes, 10, TimeUnit.MINUTES); System.out.println(i); &#125; for (; i &lt; 200; i++) &#123; redisTemplate.opsForValue().set(String.valueOf(i), bytes); System.out.println(i); &#125;&#125; 该测试结果是i为前100设置了expire的key被删除了部分，使用volatile-lru重新执行noevicationTest方法，内存不足时也会抛出异常 3、allkeys-lru，使用LRU算法（最近最少使用）删除key 测试代码 12345678910111213141516171819@Testpublic void allkeysTest() throws InterruptedException &#123; //flush db redisTemplate.delete(redisTemplate.keys(\"*\")); //1k byte[] bytes = new byte[1024]; int i = 0; for (; i &lt; 100; i++) &#123; redisTemplate.opsForValue().set(String.valueOf(i), bytes); System.out.println(i); &#125; Thread.sleep(1000); for (; i &lt; 200; i++) &#123; redisTemplate.opsForValue().set(String.valueOf(i), bytes); System.out.println(i); &#125;&#125; i为前100设置了expire的key被删除了部分，去掉sleep的话i为后100的key也被删除部分。 4、volatile-lfu，使用LFU算法删除设置了expire的key 注：使用的也是一种伪LFU算法 LFU（Least Frequently Used）算法根据数据的历史访问频率来淘汰数据，其核心思想是“如果数据过去被访问多次，那么将来被访问的频率也更高”。 执行volatileTest方法 结果同2 5、allkeys-lfu，使用LFU算法删除key 执行allKeysTest方法 结果同3 6、volatile-random，随机删除设置了expire的key 执行volatileTest方法 i为前100设置了expire的key被随机删除了部分 7、allkeys-random，随机删除key 执行allKeysTest key被随机删除部分 8、volatile-ttl，按expire删除key，越早过期的越快删除 测试代码 123456789101112@Testpublic void volatileTtlTest() &#123; //flush db redisTemplate.delete(redisTemplate.keys(\"*\")); //1k byte[] bytes = new byte[1024]; for (int i = 0; i &lt; 1000; i++) &#123; redisTemplate.opsForValue().set(String.valueOf(i), bytes, i + 1, TimeUnit.MINUTES); System.out.println(i); &#125;&#125; i为800前的key全部被删除，800后的被删除部分（极少并且基本在850之前），可见越早过期的越快删除也不是一定的，应该是跟lru、lfu一样并不能达到绝对精确的删除，个人觉得也不用绝对精确，根据项目的需要选择策略即可 写的单元测试只能算是个小demo，并没有特别去模拟LRU、LFU的场景，而且相信redis的测试肯定要比我做的要好得多了，这里就简单的了解学习一下。 代码地址：https://github.com/vickze/redis-test","tags":[{"name":"Redis","slug":"Redis","permalink":"http://blog.yk95.top/tags/Redis/"}]},{"title":"Docker学习-搭建ELK环境整合SpringBoot","date":"2019-01-30T16:00:00.000Z","path":"2019/01/31/Docker学习-搭建ELK环境整合SpringBoot/","text":"一、前提安装有Docker的Centos7虚拟机一台 了解Docker基本命令 二、Docker安装部署1、自定义网络1docker network create elk 2、安装启动Elasticsearch1docker run -d --name elasticsearch --net elk -p 9200:9200 -p 9300:9300 -e \"discovery.type=single-node\" -v /etc/timezone:/etc/timezone -v /etc/localtime:/etc/localtime elasticsearch:6.5.4 3、安装启动Kinaba1docker run -d --name kibana --net elk -p 5601:5601 -v /etc/timezone:/etc/timezone -v /etc/localtime:/etc/localtime kibana:6.5.4 4、安装启动Logstash先下载镜像然后启动容器 1docker run -d --name logstash logstash:6.5.4 复制logstash容器配置文件到主机 123docker cp logstash:/usr/share/logstash/config /usr/share/logstashdocker cp logstash:/usr/share/logstash/pipeline /usr/share/logstash 停止删除容器 123docker kill logstashdocker rm logstash 修改主机/usr/share/logstash/pipeline/logstash.conf文件，如下 1234567891011121314input &#123; tcp &#123; port =&gt; 5000 &#125;&#125;## Add your filters / logstash plugins configuration hereoutput &#123; elasticsearch &#123; hosts =&gt; \"elasticsearch:9200\" index =&gt; \"logstash-%&#123;+YYYY.MM.dd&#125;\" &#125;&#125; 可以先用一下命令启动看能否启动成功，访问主机ip：9600 验证 1docker run --rm -it --name=logstash --net=elk -p 9600:9600 -p 5000:5000 -v /usr/share/logstash/config/:/usr/share/logstash/config/ -v /usr/share/logstash/pipeline/:/usr/share/logstash/pipeline/ logstash:6.5.4 后台启动 1docker run -d --name=logstash --net=elk -p 9600:9600 -p 5000:5000 -v /usr/share/logstash/config/:/usr/share/logstash/config/ -v /usr/share/logstash/pipeline/:/usr/share/logstash/pipeline/ -v /etc/timezone:/etc/timezone -v /etc/localtime:/etc/localtime logstash:6.5.4 主机/usr/share/logstash/config/、/usr/share/logstash/pipeline/文件夹映射到logstash容器/usr/share/logstash/config/、/usr/share/logstash/pipeline/文件夹 这里还遇到个很坑的问题，linux主机跟docker容器里面的时间都不准，导致logstash收集的日志时间不对 首先校正Linux主机时间，参考https://www.cnblogs.com/zhi-leaf/p/6281549.html 同步主机时间到Docker容器，启动加-v /etc/timezone:/etc/timezone -v /etc/localtime:/etc/localtime，参考https://blog.csdn.net/dounine/article/details/79976778 也可以选择使用非官方的ELK镜像，直接搭建ELK环境。 三、SpringBoot、Logstash简单整合所谓ELK，就是Elasticsearch存储，Kibana展示，Logstash收集，这里给出一个Springboot输出日志到Logstash的简单配置 application.yml 12logging: config: classpath:logback-spring.xml logback-spring.xml 123456789101112131415161718192021222324252627&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;configuration&gt; &lt;include resource=\"org/springframework/boot/logging/logback/base.xml\"/&gt; &lt;property name=\"LOGSTASH_HOST\" value=\"$&#123;LOGSTASH_HOST:-$&#123;DOCKER_HOST:-192.168.244.137&#125;&#125;\"/&gt; &lt;property name=\"LOGSTASH_PORT\" value=\"$&#123;LOGSTASH_PORT:-5000&#125;\"/&gt; &lt;appender name=\"LOGSTASH\" class=\"net.logstash.logback.appender.LogstashTcpSocketAppender\"&gt; &lt;destination&gt;$&#123;LOGSTASH_HOST&#125;:$&#123;LOGSTASH_PORT&#125;&lt;/destination&gt; &lt;encoder charset=\"UTF-8\" class=\"net.logstash.logback.encoder.LogstashEncoder\"&gt; &lt;customFields&gt;&#123;\"appname\":\"myapp\"&#125;&lt;/customFields&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;springProfile name=\"default,dev,test\"&gt;&gt; &lt;logger name=\"io.vickze\" level=\"DEBUG\"&gt; &lt;appender-ref ref=\"LOGSTASH\"/&gt; &lt;/logger&gt; &lt;/springProfile&gt; &lt;springProfile name=\"prod\"&gt; &lt;logger name=\"io.vickze\" level=\"ERROR\"&gt; &lt;appender-ref ref=\"LOGSTASH\"/&gt; &lt;/logger&gt; &lt;/springProfile&gt;&lt;/configuration&gt; 具体代码可参考 本文只写了logstash tcp为input，output为elasticsearch的搭建与应用，logstash本身支持的input、output有几十种，具体可参考 https://www.elastic.co/guide/en/logstash/current/input-plugins.html https://www.elastic.co/guide/en/logstash/current/output-plugins.html 四、参考https://docs.docker.com/samples/library/elasticsearch/ https://docs.docker.com/samples/library/kibana/ https://docs.docker.com/samples/library/logstash/ https://www.elastic.co/guide/en/logstash/current/docker-config.html https://www.imooc.com/article/48732 https://github.com/deviantony/docker-elk/blob/master/logstash/pipeline/logstash.conf","tags":[{"name":"Docker","slug":"Docker","permalink":"http://blog.yk95.top/tags/Docker/"},{"name":"ELK","slug":"ELK","permalink":"http://blog.yk95.top/tags/ELK/"},{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://blog.yk95.top/tags/Elasticsearch/"},{"name":"Logstash","slug":"Logstash","permalink":"http://blog.yk95.top/tags/Logstash/"},{"name":"Kibana","slug":"Kibana","permalink":"http://blog.yk95.top/tags/Kibana/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://blog.yk95.top/tags/SpringBoot/"}]},{"title":"Docker学习-基础环境搭建","date":"2018-09-08T16:00:00.000Z","path":"2018/09/09/Docker学习-基础环境搭建/","text":"环境：Linux CentOS7 参考： Docker菜鸟教程 CentOS7使用firewalld打开关闭防火墙与端口 yum安装dockeryum -y install docker-io 这里安装完后还遇到个很奇怪的问题，主机ip消失了，原本用工具连着虚拟机的，突然就断了，用ip addr命令看到多了个docker0，原本主机的ip地址没了，最后通过命令service network restart重新启动网络服务就ok了。 安装完成后启动 service docker start 安装nginx拉取nginx镜像 docker pull nginx 启动nginx docker run -p 80:80 --name nginx -d nginx 命令详细：Docker命令大全 开启宿主机80端口 firewall-cmd --zone=public --add-port=80/tcp --permanent firewall-cmd --reload 访问宿主机ip可看到nginx启动页 安装mysql拉取mysql镜像 12#mysql8docker pull mysql 启动mysql 1docker run --name mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 -d mysql 命令说明： -e MYSQL_ROOT_PASSWORD=123456：初始化root用户的密码 因为mysql8的密码认证机制改了，可能我们用的mysql可视化工具并不支持，所以我们需要把mysql的密码认证改回旧版本。 进入容器 docker exec -it mysql bash 登录mysql mysql -u root -p 修改 ALTER USER &#39;root&#39;@&#39;%&#39; IDENTIFIED WITH mysql_native_password BY &#39;123456&#39;; 开启宿主机3306端口，使用宿主机ip 3306端口可以连接到mysql。 安装redis拉取redis镜像 1docker pull redis 启动redis 1docker run -p 6379:6379 --name redis -d redis 开启宿主机6379端口，使用宿主机ip 6379端口可以连接到redis。 安装rabbitmq拉取镜像 12#安装rabbitmq:management版本带管理页面docker pull rabbitmq:management 启动 1docker run -d -p 5672:5672 -p 15672:15672 --name rabbitmq rabbitmq:management 开启宿主机5672、15672端口，使用宿主机ip 5672端口连接到rabbitmq，访问宿主机ip 端口15672可以看到rabbitmq管理页面。","tags":[{"name":"Docker","slug":"Docker","permalink":"http://blog.yk95.top/tags/Docker/"},{"name":"Nginx","slug":"Nginx","permalink":"http://blog.yk95.top/tags/Nginx/"},{"name":"Mysql","slug":"Mysql","permalink":"http://blog.yk95.top/tags/Mysql/"},{"name":"Redis","slug":"Redis","permalink":"http://blog.yk95.top/tags/Redis/"},{"name":"Rabbitmq","slug":"Rabbitmq","permalink":"http://blog.yk95.top/tags/Rabbitmq/"}]},{"title":"成为Java顶尖程序员，先过了下面问题！（答案）","date":"2018-01-29T16:00:00.000Z","path":"2018/01/30/成为Java顶尖程序员，先过了下面问题！（答案）/","text":"成为Java顶尖程序员，先过了下面问题！ 答案源自网上收集及自己的一些的见解（有些知识可能理解的不对，持续修改中），部分难题只附上了链接。 一、数据结构与算法基础1、说一下几种常见的排序算法和分别的复杂度。 排序算法 平均时间复杂度 最差时间复杂度 空间复杂度 稳定性 冒泡排序 O(n&sup2;) O(n&sup2;) O(1) 稳定 选择排序 O(n&sup2;) O(n&sup2;) O(1) 稳定 插入排序 O(n&sup2;) O(n&sup2;) O(n&sup2;) 稳定 快速排序 O(n*log2n) O(n&sup2;) O(log2n)~O(n) 不稳定 2、用Java写一个冒泡排序算法123456789101112131415public void bubbleSort(int[] a) &#123; if (a == null || a.length &lt; 2) &#123; return; &#125; for (int i = a.length - 1; i &gt; 0; i--) &#123; for (int j = 0; j &lt; i; j++) &#123; if (a[j + 1] &lt; a[j]) &#123; int temp = a[j + 1]; a[j + 1] = a[j]; a[j] = temp; &#125; &#125; &#125;&#125; 3、描述一下链式存储结构。1、比顺序存储结构的存储密度小(链式存储结构中每个结点都由数据域与指针域两部分组成，相比顺序存储结构增加了存储空间)。 2、逻辑上相邻的节点物理上不必相邻。 3、插入、删除灵活 (不必移动节点，只要改变节点中的指针)。 4、查找结点时链式存储要比顺序存储慢。 5、每个结点是由数据域和指针域组成。 6、由于簇是随机分配的，这也使数据删除后覆盖几率降低，恢复可能提高。 4、如何遍历一棵二叉树？12345678910111213141516171819202122232425262728293031323334353637List&lt;List&lt;Integer&gt;&gt; print(TreeNode root) &#123; ArrayList&lt;ArrayList&lt;Integer&gt;&gt; ll = new ArrayList&lt;&gt;(); if (root == null) &#123; return ll; &#125; ArrayList&lt;Integer&gt; l = new ArrayList&lt;Integer&gt;(); TreeNode p = root; TreeNode last = null; LinkedList&lt;TreeNode&gt; queue = new LinkedList&lt;TreeNode&gt;(); queue.add(root); while (!queue.isEmpty()) &#123; TreeNode node = queue.poll(); l.add(node.val); if (node.left != null) &#123; last = node.left; queue.add(node.left); &#125; if (node.right != null) &#123; last = node.right; queue.add(node.right); &#125; if (p == node) &#123; p = last; ll.add(l); l = new ArrayList&lt;&gt;(); &#125; &#125; return ll;&#125; 5、倒排一个LinkedList1Collections.reverse(linkedList); 倒序链表可以借助Stack类或者使用递归 1234567891011121314151617181920212223242526272829public ArrayList&lt;Integer&gt; printListFromTailToHead(ListNode listNode) &#123; Stack&lt;Integer&gt; stack = new Stack&lt;Integer&gt;(); while (listNode != null) &#123; stack.push(listNode.val); listNode = listNode.next; &#125; ArrayList&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(); while (!stack.isEmpty()) &#123; list.add(stack.pop()); &#125; return list;&#125;public ArrayList&lt;Integer&gt; printListFromTailToHead(ListNode listNode) &#123; ArrayList&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(); ListNode pNode = listNode; if (pNode != null) &#123; if (pNode.next != null) &#123; list = printListFromTailToHead(pNode.next); &#125; list.add(pNode.val); &#125; return list;&#125; 6、用Java写一个递归遍历目录下面的所有文件。1234567891011121314void listAll(File directory) &#123; if (!(directory.exists() &amp;&amp; directory.isDirectory())) &#123; throw new RuntimeException(\"目录不存在\"); &#125; File[] files = directory.listFiles(); for (File file : files) &#123; System.out.println(file.getPath() + file.getName()); if (file.isDirectory()) &#123; listAll(file); &#125; &#125;&#125; 二、Java基础1、接口与抽象类的区别？类可以实现多个接口但只能继承一个抽象类 接口里面所有的方法都是Public的，抽象类允许Private、Protected方法 JDK8前接口里面所有的方法都是抽象的且不允许有静态方法，抽象类可以有普通、静态方法，JDK8 接口可以实现默认方法和静态方法，前面加default、static关键字 2、Java中的异常有哪几类？分别怎么使用？分为错误和异常，异常又包括运行时异常、非运行时异常 错误，如StackOverflowError、OutOfMemoryError 运行时异常，如NullPointerException、IndexOutOfBoundsException，都是RuntimeException及其子类 非运行时异常，如IOException、SQLException,都是Exception及其子类，这些异常是一定需要try catch捕获的 3、常用的集合类有哪些？比如List如何排序？主要分为三类，Map、Set、List Map: HashMap、LinkedHashMap、TreeMap Set：HashSet、LinkedHashSet、TreeSet List: ArrayList、LinkedList 1Collections.sort(list); 4、ArrayList和LinkedList内部的实现大致是怎样的？他们之间的区别和优缺点？ArrayList：内部使用数组的形式实现了存储，利用数组的下标进行元素的访问，因此对元素的随机访问速度非常快。因为是数组，所以ArrayList在初始化的时候，有初始大小10，插入新元素的时候，会判断是否需要扩容，扩容的步长是0.5倍原容量，扩容方式是利用数组的复制，因此有一定的开销。 LinkedList：内部使用双向链表的结构实现存储，LinkedList有一个内部类作为存放元素的单元，里面有三个属性，用来存放元素本身以及前后2个单元的引用，另外LinkedList内部还有一个header属性，用来标识起始位置，LinkedList的第一个单元和最后一个单元都会指向header，因此形成了一个双向的链表结构。 ArrayList查找较快，插入、删除较慢，LinkedList查找较慢，插入、删除较快。 5、内存溢出是怎么回事？请举一个例子？内存溢出 out of memory，是指程序在申请内存时，没有足够的内存空间供其使用，出现out of memory。 内存泄漏 memory leak，是指程序在申请内存后，无法释放已申请的内存空间，一次内存泄漏危害可以忽略，但内存泄漏堆积后果很严重，无论多少内存,迟早会被占光。 1234List&lt;Object&gt; list = new ArrayList&lt;&gt;();while (true) &#123; list.add(new Object());&#125; 内存溢出可能的原因: 1、程序中存在死循环 2、静态变量和静态方法太多了 3、内存泄漏，比如说一个静态的list，一直往里放值，又因为静态变量不会被释放，所以迟早是要内存溢出的 4、大对象过多，java中的大对象是直接进入老年代的，然后当多个大对象同时工作时造成程序的可用内存非常小，比如我list中原本最多可以放1000个对象，因为可用内存太小，放了500个就放不下了。 5、还有一种很常见的情况，在把一个很大的程序直接导入，直接就内存溢出了，原因就是内存相对这个程序就是太小了，需要手动增加内存。 6、==和equals的区别？==是运算符，而equals是Object的基本方法，==用于基本类型的数据的比较，或者是比较两个对象的引用是否相同，equals用于比较两个对象的值是否相等，例如字符串的比较 7、hashCode方法的作用？1、hashCode的存在主要是用于查找的快捷性，为了配合基于散列的集合正常运行，如Hashtable，HashMap等，hashCode是用来在散列存储结构中确定对象的存储地址的； 2、如果两个对象相同，就是适用于equals(java.lang.Object) 方法，那么这两个对象的hashCode一定要相同； 3、如果对象的equals方法被重写，那么对象的hashCode也尽量重写，并且产生hashCode使用的对象，一定要和equals方法中使用的一致，否则就会违反上面提到的第2点； 4、两个对象的hashCode相同，并不一定表示两个对象就相同，也就是不一定适用于equals(java.lang.Object) 方法，只能够说明这两个对象在散列存储结构中，它们存放在同一个桶里面 8、NIO是什么？适用于何种场景？NIO是为了弥补IO操作的不足而诞生的，NIO的一些新特性有：非阻塞I/O，选择器，缓冲以及管道。管道（Channel），缓冲（Buffer） ，选择器（ Selector）是其主要特征。 如果需要管理同时打开的成千上万个连接，这些连接每次只是发送少量的数据，例如聊天服务器，这时候用NIO处理数据可能是个很好的选择。 而如果只有少量的连接，而这些连接每次要发送大量的数据，这时候传统的IO更合适。使用哪种处理数据，需要在数据的响应等待时间和检查缓冲区数据的时间上作比较来权衡选择。 Java中NIO和IO区别和适用场景 9、HashMap实现原理，如何保证HashMap的线程安全？ java 8 Hashmap深入解析 —— put get 方法源码 HashMap是基于哈希表（链地址法）实现的，在JDK8中，当数组中链表长度大于8会转为红黑树。 1Collections.synchronizedMap(map); 10、JVM内存结构，为什么需要GC？ 名称 特征 作用 配置参数 异常 程序计数器 占用内存小，线程私有，生命周期与线程相同 大致为字节码行号指示器 无 无 虚拟机栈 线程私有，生命周期与线程相同，使用连续的内存空间 Java方法执行的内存模型，存储局部变量表、操作栈、动态链接、方法出口等信息 -Xss StackOverflowError OutOfMemoryError 堆 线程共享，生命周期与虚拟机相同，可以不使用连续的内存地址 保存对象实例，所有对象（包括数组）都要在堆上分配 -Xms -Xmx -Xmn OutOfMemoryError 方法区 线程共享，生命周期与虚拟机相同，可以不使用连续的内存地址 存储已被虚拟机加载的类信息、常量、静态变量、即时编译器后的代码等数据 -XX:PermSize:16M -XX:MaxPermSize:64M OutOfMemoryError 运行时常量池 方法区的一部分，具有动态性 存放字面量及符号引用 无 无 垃圾回收可以有效的防止内存泄漏，有效的使用可以使用的内存。垃圾回收器通常是作为一个单独的低优先级的线程运行，不可预知的情况下对内存堆中已经死亡的或者长时间没有使用的对象进行清除和回收，程序员不能实时的调用垃圾回收器对某个对象或所有对象进行垃圾回收。回收机制有分代复制垃圾回收、标记垃圾回收、增量垃圾回收等方式。 11、NIO模型，select/epoll的区别，多路复用的原理select，poll，epoll都是IO多路复用的机制。I/O多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。 （1）select，poll实现需要自己不断轮询所有fd集合，直到设备就绪，期间可能要睡眠和唤醒多次交替。而epoll其实也需要调用epoll_wait不断轮询就绪链表，期间也可能多次睡眠和唤醒交替，但是它是设备就绪时，调用回调函数，把就绪fd放入就绪链表中，并唤醒在epoll_wait中进入睡眠的进程。虽然都要睡眠和交替，但是select和poll在“醒着”的时候要遍历整个fd集合，而epoll在“醒着”的时候只要判断一下就绪链表是否为空就行了，这节省了大量的CPU时间。这就是回调机制带来的性能提升。 （2）select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，并且要把current往设备等待队列中挂一次，而epoll只要一次拷贝，而且把current往等待队列上挂也只挂一次（在epoll_wait的开始，注意这里的等待队列并不是设备等待队列，只是一个epoll内部定义的等待队列）。这也能节省不少的开销。 select、poll、epoll之间的区别总结[整理] 12、Java中一个字符占多少个字节，扩展再问int, long, double占多少字节1字节： byte , boolean 2字节： short , char 4字节： int , float 8字节： long , double 13、创建一个类的实例都有哪些办法？12345Object o = new Object();Object o = oo.clone();Object o = Class.forName(\"xxx\").newInstance(); 14、final/finally/finalize的区别？final是定义类、方法、字段的修饰符，表示类不可被继承，方法不能被重写，字段值不能被修改 finally是异常处理机制的关键字，表示最后执行 finalize是Object的一个方法，在对象被虚拟机回收时会判断是否执行该方法，当对象没有覆盖finalize方法，或者finalize方法已经被虚拟机调用过，虚拟机将这两种情况都视为“没有必要执行” 15、Session/Cookie的区别？Session存储在服务器端，类型可以是任意的Java对象，Cookie存储在客户端，类型只能为字符串 16、String/StringBuffer/StringBuilder的区别，扩展再问他们的实现？String、StringBuffer是线程安全的，StringBuilder不是 String不继承任何类，StringBuffer、StringBuilder继承自AbstractStringBuilder 17、Servlet的生命周期？Servlet生命周期分为三个阶段： 1、初始化阶段 调用init()方法 2、响应客户请求阶段 调用service()方法 3、终止阶段 调用destroy()方法 Servlet初始化阶段： 在下列时刻Servlet容器装载Servlet： 1、Servlet容器启动时自动装载某些Servlet，实现它只需要在web.XML文件中的之间添加如下代码： 1&lt;loadon-startup&gt;1&lt;/loadon-startup&gt; 2、在Servlet容器启动后，客户首次向Servlet发送请求 3、Servlet类文件被更新后，重新装载Servlet Servlet被装载后，Servlet容器创建一个Servlet实例并且调用Servlet的init()方法进行初始化。在Servlet的整个生命周期内，init()方法只被调用一次。 18、如何用Java分配一段连续的1G的内存空间？需要注意些什么？1ByteBuffer.allocateDirect(1024*1024*1024); 要注意内存溢出的问题 19、Java有自己的内存回收机制，但为什么还存在内存泄漏的问题呢？首先内存泄漏 memory leak，是指程序在申请内存后，无法释放已申请的内存空间，一次内存泄漏危害可以忽略，但内存泄漏堆积后果很严重，无论多少内存,迟早会被占光。 比如下面这段代码，list持有o的引用，o暂时是无法被JVM垃圾回收的，只有当list被垃圾回收或者o从对象list删除掉后，o才能被JVM垃圾回收。 1234List&lt;Object&gt; list = new ArrayList&lt;&gt;();Object o = new Object();list.add(o);o = null; 20、什么是java序列化，如何实现java序列化?(写一个实例)？Java序列化就是把对象扁平化成一组数据，通过这组数据可以反序列化回Java对象。 例：序列化二叉树 12345678910111213141516171819202122232425262728293031private int index = -1;String Serialize(TreeNode root) &#123; StringBuilder sb = new StringBuilder(); if (root == null) &#123; sb.append(\"#,\"); return sb.toString(); &#125; sb.append(root.val + \",\"); sb.append(Serialize(root.left)); sb.append(Serialize(root.right)); return sb.toString();&#125;TreeNode Deserialize(String str) &#123; index++; String[] strs = str.split(\",\"); if (index &gt; strs.length || strs[index].equals(\"#\")) &#123; return null; &#125; TreeNode root = new TreeNode(Integer.parseInt(strs[index])); root.left = Deserialize(str); root.right = Deserialize(str); return root;&#125; 21、String s = new String(“abc”);创建了几个 String Object?2个，会创建String对象存放在字符串常量池跟堆中。 三、JVM1、JVM堆的基本结构。在JVM中堆空间划分如下图所示 上图中，刻画了Java程序运行时的堆空间,可以简述成如下2条 1、JVM中堆空间可以分成三个大区，新生代、老年代、永久代 2、新生代可以划分为三个区，Eden区，两个Survivor区，在HotSpot虚拟机Eden和Survivor的大小比例为8:1 2、JVM的垃圾算法有哪几种？CMS垃圾回收的基本流程？四种：标记-清除算法、复制算法、标记-整理算法、分代收集算法 垃圾收集器有七种：Serial、ParNew、Parallel Scavenge、CMS、Serial Old、Parrallel Old、G1 CMS全称为Concurrent Mark Sweep，是一款并发、使用标记-清除算法的gc收集器。 总体来说CMS的执行过程可以分为以下几个阶段：初始标记 -&gt; 并发标记 -&gt; 重新标记 -&gt; 并发清理 -&gt; 重置 3、JVM有哪些常用启动参数可以调整，描述几个？java–jvm启动的参数 Java启动参数及调优 java启动参数共分为三类； 其一是标准参数（-），所有的JVM实现都必须实现这些参数的功能，而且向后兼容；其二是非标准参数（-X），默认jvm实现这些参数的功能，但是并不保证所有jvm实现都满足，且不保证向后兼容；其三是非Stable参数（-XX），此类参数各个jvm实现会有所不同，将来可能会随时取消，需要慎重使用； 一、标准参数 参数 作用 -client 设置jvm使用client模式，特点是启动速度比较快，但运行时性能和内存管理效率不高，通常用于客户端应用程序或者PC应用开发和调试。 -server 设置jvm使server模式，特点是启动速度比较慢，但运行时性能和内存管理效率很高，适用于生产环境。在具有64位能力的jdk环境下将默认启用该模式，而忽略-client参数。 -jar 指定以jar包的形式执行一个应用程序。要这样执行一个应用程序，必须让jar包的manifest文件中声明初始加载的Main-class，当然那Main-class必须有public static void main(String[] args)方法。 -agentlib:libname [=options] 用于装载本地lib包；其中 libname为本地代理库文件名，默认搜索路径为环境变量PATH中的路径，options为传给本地库启动时的参数，多个参数之间用逗号分隔。在 Windows平台上jvm搜索本地库名为libname.dll的文件，在linux上jvm搜索本地库名为libname.so的文件，搜索路径环境变量在不同系统上有所不同，比如Solaries上就默认搜索LD_LIBRARY_PATH。比如：-agentlib:hprof用来获取jvm的运行情况，包括CPU、内存、线程等的运行数据，并可输出到指定文件中；windows中搜索路径为JRE_HOME/bin/hprof.dll。 -agentpath:pathname [=options] 按全路径装载本地库，不再搜索PATH中的路径；其他功能和agentlib相同；更多的信息待续，在后续的JVMTI部分会详述。 -javaagent:jarpath [=options] 指定jvm启动时装入java语言设备代理。Jarpath 文件中的mainfest文件必须有Agent-Class属性。代理类也必须实现公共的静态public static void premain(String agentArgs, Instrumentation inst)方法（和main方法类似）。当jvm初始化时，将按代理类的说明顺序调用premain方法；具体参见 java.lang.instrument软件包的描述。 -classpath classpath或-cp classpath 告知jvm搜索目录名、jar文档名、zip文档名，之间用分号;分隔；使用-classpath后jvm将不再使用CLASSPATH中的类搜索路径，如果-classpath和CLASSPATH都没有设置，则jvm使用当前路径(.)作为类搜索路径。jvm搜索类的方式和顺序为：Bootstrap，Extension，User。Bootstrap中的路径是jvm自带的jar或zip文件，jvm首先搜索这些包文件，用System.getProperty(“sun.boot.class.path”)可得到搜索路径。Extension是位于JRE_HOME/lib/ext目录下的jar文件，jvm在搜索完Bootstrap后就搜索该目录下的jar文件，用System.getProperty(“java.ext.dirs”)可得到搜索路径。User搜索顺序为当前路径.、CLASSPATH、-classpath，jvm最后搜索这些目录，用System.getProperty(“java.class.path”)可得到搜索路径。 -Dproperty=value 设置系统属性名/值对，运行在此jvm之上的应用程序可用System.getProperty(“property”)得到value的值。如果value中有空格，则需要用双引号将该值括起来，如-Dname=”space string”。该参数通常用于设置系统级全局变量值，如配置文件路径，以便该属性在程序中任何地方都可访问。 -verbose -verbose:class 输出jvm载入类的相关信息，当jvm报告说找不到类或者类冲突时可此进行诊断。 -verbose:gc 输出每次GC的相关情况。 -verbose:jni 输出native方法调用的相关情况，一般用于诊断jni调用错误信息。 -version 输出java的版本信息，比如jdk版本、vendor、model。 二、非标准参数 参数 描述 -Xms(n) 指定jvm堆的初始大小，默认为物理内存的1/64，最小为1M；可以指定单位，比如k、m，若不指定，则默认为字节。 -Xmx(n) 指定jvm堆的最大值，默认为物理内存的1/4或者1G，最小为2M；单位与-Xms一致。 -Xmn(n) 指定jvm堆中年轻代的大小 -Xss(n) 设置单个线程栈的大小，一般默认为512k。 -Xint 设置jvm以解释模式运行，所有的字节码将被直接执行，而不会编译成本地码。 -Xbatch 关闭后台代码编译，强制在前台编译，编译完成之后才能进行代码执行；默认情况下，jvm在后台进行编译，若没有编译完成，则前台运行代码时以解释模式运行。 -Xbootclasspath:bootclasspath 让jvm从指定路径（可以是分号分隔的目录、jar、或者zip）中加载bootclass，用来替换jdk的rt.jar；若非必要，一般不会用到； -Xbootclasspath/a:path 将指定路径的所有文件追加到默认bootstrap路径中； -Xbootclasspath/p:path 让jvm优先于bootstrap默认路径加载指定路径的所有文件； -Xcheck:jni 对JNI函数进行附加check；此时jvm将校验传递给JNI函数参数的合法性，在本地代码中遇到非法数据时，jmv将报一个致命错误而终止；使用该参数后将造成性能下降，请慎用。 -Xfuture 让jvm对类文件执行严格的格式检查（默认jvm不进行严格格式检查），以符合类文件格式规范，推荐开发人员使用该参数。 -Xnoclassgc 关闭针对class的gc功能；因为其阻止内存回收，所以可能会导致OutOfMemoryError错误，慎用； -Xincgc 开启增量gc（默认为关闭）；这有助于减少长时间GC时应用程序出现的停顿；但由于可能和应用程序并发执行，所以会降低CPU对应用的处理能力。 -Xloggc:file 与-verbose:gc功能类似，只是将每次GC事件的相关情况记录到一个文件中，文件的位置最好在本地，以避免网络的潜在问题。若与verbose命令同时出现在命令行中，则以-Xloggc为准。 -Xprof 跟踪正运行的程序，并将跟踪数据在标准输出输出；适合于开发环境调试。 -Xrs 减少jvm对操作系统信号（signals）的使用，该参数从1.3.1开始有效；从jdk1.3.0开始，jvm允许程序在关闭之前还可以执行一些代码（比如关闭数据库的连接池），即使jvm被突然终止；jvm 关闭工具通过监控控制台的相关事件而满足以上的功能；更确切的说，通知在关闭工具执行之前，先注册控制台的控制handler，然后对 CTRL_C_EVENT, CTRL_CLOSE_EVENT,CTRL_LOGOFF_EVENT, and CTRL_SHUTDOWN_EVENT这几类事件直接返回true。但如果jvm以服务的形式在后台运行（比如servlet引擎），他能接收CTRL_LOGOFF_EVENT事件，但此时并不需要初始化关闭程序；为了避免类似冲突的再次出现，从jdk1.3.1开始提供-Xrs参数；当此参数被设置之后，jvm将不接收控制台的控制handler，也就是说他不监控和处理CTRL_C_EVENT, CTRL_CLOSE_EVENT, CTRL_LOGOFF_EVENT, orCTRL_SHUTDOWN_EVENT事件。 三、非Stable参数 前面我们提到用-XX作为前缀的参数列表在jvm中可能是不健壮的，SUN也不推荐使用，后续可能会在没有通知的情况下就直接取消了；但是由于这些参数中的确有很多是对我们很有用的，比如我们经常会见到的-XX:PermSize、-XX:MaxPermSize等等； 下面我们将就Java HotSpot VM中-XX:的可配置参数列表进行描述；这些参数可以被松散的聚合成三类：行为参数（Behavioral Options）：用于改变jvm的一些基础行为；性能调优（Performance Tuning）：用于jvm的性能调优；调试参数（Debugging Options）：一般用于打开跟踪、打印、输出等jvm参数，用于显示jvm更加详细的信息； 由于sun官方文档中对各参数的描述也都非常少（大多只有一句话），而且大多涉及OS层面的东西，很难描述清楚，所以以下是挑选了一些我们开发中可能会用得比较多的配置项。 首先来介绍行为参数： 参数 描述 -XX:-DisableExplicitGC 禁止调用System.gc()；但jvm的gc仍然有效 -XX:+MaxFDLimit 最大化文件描述符的数量限制 -XX:+ScavengeBeforeFullGC 新生代GC优先于Full GC执行 -XX:+UseGCOverheadLimit 在抛出OOM之前限制jvm耗费在GC上的时间比例 -XX:-UseConcMarkSweepGC 对老生代采用并发标记交换算法进行GC -XX:-UseParallelGC 启用并行GC -XX:-UseParallelOldGC 对Full GC启用并行，当-XX:-UseParallelGC启用时该项自动启用 -XX:-UseSerialGC 启用串行GC -XX:+UseThreadPriorities 启用本地线程优先级 上面表格中黑体的三个参数代表着jvm中GC执行的三种方式，即串行、并行、并发； 串行（SerialGC）是jvm的默认GC方式，一般适用于小型应用和单处理器，算法比较简单，GC效率也较高，但可能会给应用带来停顿； 并行（ParallelGC）是指GC运行时，对应用程序运行没有影响，GC和app两者的线程在并发执行，这样可以最大限度不影响app的运行； 并发（ConcMarkSweepGC）是指多个线程并发执行GC，一般适用于多处理器系统中，可以提高GC的效率，但算法复杂，系统消耗较大； 性能调优参数列表： 参数及其默认值 描述 -XX:LargePageSizeInBytes=4m 设置用于Java堆的大页面尺寸 -XX:MaxHeapFreeRatio=70 GC后java堆中空闲量占的最大比例 -XX:MinHeapFreeRatio=40 GC后java堆中空闲量占的最小比例 -XX:MaxNewSize=size 新生代占用内存的最大值 -XX:PermSize 表示非堆区初始内存分配大小，其缩写为permanent size（持久化内存） -XX:MaxPermSize=64m 表示对非堆区分配的内存的最大上限 -XX:NewRatio=2 新生代内存容量与老生代内存容量的比例 -XX:SurvivorRatio 新生代中survivor区和eden区的比例 -XX:NewSize=2.125m 新生代占用内存的初始值 -XX:ReservedCodeCacheSize=32m 保留代码占用的内存容量 -XX:ThreadStackSize=512 设置线程栈大小，若为0则使用系统默认值 -XX:+UseLargePages 使用大页面内存 调试参数列表： 参数及其默认值 描述 -XX:-CITime 打印消耗在JIT编译的时间 -XX:ErrorFile=./hs_err_pid.log 保存错误日志或者数据到文件中 -XX:-ExtendedDTraceProbes 开启solaris特有的dtrace探针 -XX:HeapDumpPath=./java_pid.hprof 指定导出堆信息时的路径或文件名 -XX:-HeapDumpOnOutOfMemoryError 当首次遭遇OOM时导出此时堆中相关信息 -XX:OnError=”” 出现致命ERROR之后运行自定义命令 -XX:OnOutOfMemoryError=”” 当首次遭遇OOM时执行自定义命令 -XX:-PrintClassHistogram 遇到Ctrl-Break后打印类实例的柱状信息，与jmap -histo功能相同 -XX:-PrintConcurrentLocks 遇到Ctrl-Break后打印并发锁的相关信息，与jstack -l功能相同 -XX:-PrintCommandLineFlags 打印在命令行中出现过的标记 -XX:-PrintCompilation 当一个方法被编译时打印相关信息 -XX:-PrintGC 每次GC时打印相关信息 -XX:-PrintGC Details 每次GC时打印详细信息 -XX:-PrintGCTimeStamps 打印每次GC的时间戳 -XX:-TraceClassLoading 跟踪类的加载信息 -XX:-TraceClassLoadingPreorder 跟踪被引用到的所有类的加载信息 -XX:-TraceClassResolution 跟踪常量池 -XX:-TraceClassUnloading 跟踪类的卸载信息 -XX:-TraceLoaderConstraints 跟踪类加载器约束的相关信息 4、如何查看JVM的内存使用情况？可以使用JDK自带的JConsole、JVisualVM、JMap、JHat等工具，或者使用第三方工具，比如 Eclipse Memory Analyzer 5、Java程序是否会内存溢出，内存泄漏情况发生？举几个例子。内存溢出，比如给JVM分配的内存不够大，或者程序中存在死循环一直申请内存。 内存泄露，比如下面这段代码，list持有o的引用，o暂时是无法被JVM垃圾回收的，只有当list被垃圾回收或者o从对象list删除掉后，o才能被JVM垃圾回收。 1234List&lt;Object&gt; list = new ArrayList&lt;&gt;();Object o = new Object();list.add(o);o = null; 6、你常用的JVM配置和调优参数都有哪些？分别什么作用？参考 3、JVM有哪些常用启动参数可以调整，描述几个？ 7、JVM的内存结构？see 10、JVM内存结构，为什么需要GC? 8、常用的GC策略，什么时候会触发YGC，什么时候触发FGC？YGC(Young GC)：对新生代堆进行GC。频率比较高，因为大部分对象的存活寿命较短，在新生代里被回收。性能耗费较小。 FGC(Full GC)：全堆范围的GC。默认堆空间使用到达80%(可调整)的时候会触发FGC。以我们生产环境为例，一般比较少会触发FGC，有时10天或一周左右会有一次。 YGC的时机: 1、Eden区空间不足 FGC的时机： 1、Old空间不足； 2、Perm空间不足； 3、显示调用System.gc() ，包括RMI等的定时触发; 4、YGC时的悲观策略； 5、dump live的内存信息时(jmap –dump:live)。 对YGC的 触发时机，相当的显而易见，就是Eden区空间不足， 这时候就肯定会触发YGC 对于FGC的触发时机， old空间不足， 和perm的空间不足， 调用system.gc()这几个都比较显而易见，就是在这种情况下， 一般都会触发GC。 最复杂的是所谓的悲观策略，它触发的机制是在首先会计算之前晋升的平均大小，也就是从新生代，通过YGC变成新生代的平均大小，然后如果旧生代剩余的空间小于晋升大小，那么就会触发一次FullGC。sdk考虑的策略是， 从平均和长远的情况来看，下次晋升空间不够的可能性非常大， 与其等到那时候在FullGC 不如悲观的认为下次肯定会触发FullGC， 直接先执行一次FullGC。而且从实际使用过程中来看， 也达到了比较稳定的效果。 四、多线程/并发1、如何创建线程？如何保证线程安全？继承Thread类，实现Runnable接口，使用Executor框架来创建线程池。 使用volatile、synchronized关键字或者Jdk的各种并发API可以保证线程安全 2、什么是死锁？如何避免死锁是两个或两个以上的线程都在等待对方执行完毕才能往下执行下去，结果就是所有的线程都陷入的无限的等待当中； 死锁的发生有着四个必要条件，分别是互斥性，请求和保持，不可剥夺和循环等待条件，只要破坏了任意条件死锁就不会发生，最简单的方法就是线程以同样的顺序加锁和释放锁，也就是破坏了第四个条件。 3、Volatile关键字的作用？保证变量的可见性，即读取的变量值一定是最新的，并不能保证线程安全 4、HashMap在多线程环境下使用需要注意什么？为什么？要注意死循环的问题，HashMap的put操作可以造成重新分配存储大小resize的动作，这个动作在多线程并发下会发生线程死循环的问题。 5、Java程序中启动一个线程是用run()还是start()？start() 6、什么是守护线程？有什么用？守护线程（即daemon thread），是个服务线程，准确地来说就是服务其他的线程，这是它的作用——而其他的线程只有一种，那就是用户线程。所以java里线程分2种， 1、守护线程，比如垃圾回收线程，就是最典型的守护线程。 2、用户线程，就是应用程序里的自定义线程。 7、线程和进程的差别是什么？进程是执行着的应用程序，线程是进程的一个执行序列，一个进程可以有多个线程。 8、Java里面的Threadlocal是怎样实现的？ThreadLocal：线程局部变量。为每一个使用该变量的线程都提供一个变量值的副本，是每一个线程都可以独立地改变自己的副本，而不会和其它线程的副本冲突。从线程的角度看，就好像每一个线程都完全拥有该变量。 每个运行的线程都会有一个类型为ThreadLocal.ThreadLocalMap的map,这个map就是用来存储与这个线程绑定的变量。 9、ConcurrentHashMap的实现原理是？在jdk1.6中ConcurrentHashMap使用锁分段技术提高并发访问效率。首先将数据分成一段一段地存储，然后给每一段数据配一个锁，当一个线程占用锁访问其中一段数据时，其他段的数据也能被其他线程访问。然而在jdk1.8中的实现已经抛弃了Segment分段锁机制，利用CAS+Synchronized来保证并发更新的安全，底层依然采用数组+链表+红黑树的存储结构。 附：深入浅出CAS 10、sleep和wait区别调用sleep方法不会释放锁，调用wait方法会释放锁 12、notify和notifyAll区别notify唤醒一个处于wait状态的线程，notifyAll唤醒所有处于wait状态的线程，它们的相同点是最终只会有一个线程获得锁 13、两个线程如何串行执行加锁 14、上下文切换是什么含义上下文切换是存储和恢复线程状态的过程，它使得线程执行能够从中断点恢复执行。上下文切换是多任务操作系统和多线程环境的基本特征。 15、可以运行时kill掉一个线程吗？不可以，线程有5种状态，新建（new）、可运行（runnable）、运行中（running）、阻塞（block）、死亡（dead）。 只有当线程run方法或者主线程main方法结束，又或者抛出异常时，线程才会结束生命周期。 16、什么是条件锁、读写锁、自旋锁、可重入锁？https://www.cnblogs.com/my376908915/p/6758681.html http://blog.csdn.net/a314773862/article/details/54095819 17、线程池ThreadPoolExecutor的实现原理？深入分析java线程池的实现原理 五、Linux使用与问题分析排查1、使用两种命令创建一个文件？touch filename 建立一个空文件 cat &gt; filename 建立一文件，然后把接下来的键盘输入写入文件，直到按Ctrl+D为止 2、硬链接和软链接的区别？硬链接： 1、文件有相同的 inode 及 data block； 2、只能对已存在的文件进行创建； 3、不能交叉文件系统进行硬链接的创建； 4、不能对目录进行创建，只可对文件创建； 5、删除一个硬链接文件并不影响其他有相同 inode 号的文件。 软连接： 1、软链接有自己的文件属性及权限等； 2、可对不存在的文件或目录创建软链接； 3、软链接可交叉文件系统； 4、软链接可对文件或目录创建； 5、创建软链接时，链接计数 i_nlink 不会增加； 6、删除软链接并不影响被指向的文件，但若被指向的原文件被删除，则相关软连接被称为死链接（即 dangling link，若被指向路径文件被重新创建，死链接可恢复为正常的软链接）。 3、Linux常用命令有哪些？初窥Linux之我最常用的20条命令 我的常用： 查找关闭端口进程 netstat -nlp | grep :3306 kill pid 删除文件 rm -rf 查找日志 cat xx.log | grep &#39;xxx&#39; | more 解压tar.gz tar -xzvf file.tar.gz 创建文件 touch filename cat &gt; filename 修改文件 vi 4、怎么看一个Java线程的资源耗用？linux下，所有的java内部线程，其实都对应了一个进程id，也就是说，linux上的jvm将java程序中的线程映射为操作系统进程。 1、jps -lvm或者ps -ef | grep java查看当前机器上运行的Java应用进程 2、top -Hp pid可以查看Java所有线程的资源耗用 4、printf &quot;%x\\n&quot; pid等到线程ID的16进制 5、jstack Java应用进程ID | grep 线程ID的16进制 5、Load过高的可能性有哪些？cpu load过高问题排查 cpu load的飙升，一方面可能和full gc的次数增大有关，一方面可能和死循环有关系 6、/etc/hosts文件什么作用？在当前主机给ip设置别名，通过该别名可以访问到该ip地址，通过别名、ip访问的效果是一样的 7、如何快速的将一个文本中所有“abc”替换为“xyz”？vi filename编辑文本，按Esc键，输入:%s/abc/xyz/g 8、如何在log文件中搜索找出error的日志？cat xx.log | grep &#39;error&#39; 9、发现磁盘空间不够，如何快速找出占用空间最大的文件？Linux下查找大文件，大目录的方法 find . -type f -size +100M | xargs du -h | sort -nr 10、Java服务端问题排查（OOM，CPU高，Load高，类冲突）java线上服务问题排查 11、Java常用问题排查工具及用法（top, iostat, vmstat, sar, tcpdump, jvisualvm, jmap, jconsole）Java自带的性能监测工具用法简介——jstack、jconsole、jinfo、jmap、jdb、jsta、jvisualvm 12、Thread dump文件如何分析（Runnable，锁，代码栈，操作系统线程ID关联）性能分析之– JAVA Thread Dump 分析综述 13、如何查看Java应用的线程信息？参考 4、怎么看一个Java线程的资源耗用？ 通过top命令拿到线程的pid后使用jstack命令 六、框架使用1、描述一下Hibernate的三个状态？transient(瞬时状态)：new出来一个对象，还没被保存到数据库中 persistent(持久化状态)：对象已经保存到数据库中并且在hibernate session也存在该对象 detached(离线状态)：对象在数据库中存在，hibernate session不存在 2、Spring中Bean的生命周期。 1、Spring对Bean进行实例化（相当于程序中的new Xx()） 2、Spring将值和Bean的引用注入进Bean对应的属性中 3、如果Bean实现了BeanNameAware接口，Spring将Bean的ID传递给setBeanName()方法（实现BeanNameAware清主要是为了通过Bean的引用来获得Bean的ID，一般业务中是很少有用到Bean的ID的） 4、如果Bean实现了BeanFactoryAware接口，Spring将调用setBeanDactory(BeanFactory bf)方法并把BeanFactory容器实例作为参数传入。（实现BeanFactoryAware 主要目的是为了获取Spring容器，如Bean通过Spring容器发布事件等） 5、如果Bean实现了ApplicationContextAwaer接口，Spring容器将调用setApplicationContext(ApplicationContext ctx)方法，把y应用上下文作为参数传入.(作用与BeanFactory类似都是为了获取Spring容器，不同的是Spring容器在调用setApplicationContext方法时会把它自己作为setApplicationContext 的参数传入，而Spring容器在调用setBeanDactory前需要程序员自己指定（注入）setBeanDactory里的参数BeanFactory ) 7、如果Bean实现了BeanPostProcess接口，Spring将调用它们的postProcessBeforeInitialization（预初始化）方法（作用是在Bean实例创建成功后对进行增强处理，如对Bean进行修改，增加某个功能）7.如果Bean实现了InitializingBean接口，Spring将调用它们的afterPropertiesSet方法，作用与在配置文件中对Bean使用init-method声明初始化的作用一样，都是在Bean的全部属性设置成功后执行的初始化方法。 8、如果Bean实现了BeanPostProcess接口，Spring将调用它们的postProcessAfterInitialization（后初始化）方法（作用与7的一样，只不过7是在Bean初始化前执行的，而这个是在Bean初始化后执行的，时机不同 ) 9、经过以上的工作后，Bean将一直驻留在应用上下文中给应用使用，直到应用上下文被销毁 10、如果Bean实现了DispostbleBean接口，Spring将调用它的destory方法，作用与在配置文件中对Bean使用destory-method属性的作用一样，都是在Bean实例销毁前执行的方法。 3、SpringMVC或Struts处理请求的流程。SpringMVC与Struts2的区别及执行流程 springmvc全称是spring web mvc，是spring框架一部分，是一个mvc的框架，和struts2一样是一个表现层框架。 springMVC的执行流程： 1、 用户发送请求至前端控制器DispatcherServlet 2、 DispatcherServlet收到请求调用HandlerMapping处理器映射器查找Handler。 3、 处理器映射器根据请求url找到具体的处理器，生成处理器对象及处理器拦截器(如果有则生成)一并返回给DispatcherServlet。 4、 DispatcherServlet通过HandlerAdapter处理器适配器调用处理器 5、 HandlerAdapter调用处理器Handler 6、 Handler执行完成返回ModelAndView 7、 HandlerAdapter将Handler执行结果ModelAndView返回给DispatcherServlet 8、 DispatcherServlet将ModelAndView传给ViewReslover视图解析器，ViewReslover根据逻辑视图名解析View 9、 ViewReslover返回View 10、 DispatcherServlet对View进行渲染视图（即将模型数据填充至request域）。 11、 DispatcherServlet响应用户 4、Spring AOP解决了什么问题？怎么实现的？Spring AOP 实现原理 5、Spring事务的传播属性是怎么回事？它会影响什么？七个事务传播属性： PROPAGATION_REQUIRED – 支持当前事务，如果当前没有事务，就新建一个事务。这是最常见的选择。 PROPAGATION_SUPPORTS – 支持当前事务，如果当前没有事务，就以非事务方式执行。 PROPAGATION_MANDATORY – 支持当前事务，如果当前没有事务，就抛出异常。 PROPAGATION_REQUIRES_NEW – 新建事务，如果当前存在事务，把当前事务挂起。 PROPAGATION_NOT_SUPPORTED – 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。 PROPAGATION_NEVER – 以非事务方式执行，如果当前存在事务，则抛出异常。 PROPAGATION_NESTED – 如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则进行与PROPAGATION_REQUIRED类似的操作。 五个隔离级别： ISOLATION_DEFAULT 这是一个PlatfromTransactionManager默认的隔离级别，使用数据库默认的事务隔离级别. 另外四个与JDBC的隔离级别相对应： ISOLATION_READ_UNCOMMITTED 这是事务最低的隔离级别，它充许别外一个事务可以看到这个事务未提交的数据。这种隔离级别会产生脏读，不可重复读和幻读。 ISOLATION_READ_COMMITTED 保证一个事务修改的数据提交后才能被另外一个事务读取。另外一个事务不能读取该事务未提交的数据。这种事务隔离级别可以避免脏读出现，但是可能会出现不可重复读和幻读。 ISOLATION_REPEATABLE_READ 这种事务隔离级别可以防止脏读，不可重复读。但是可能出现幻读。它除了保证一个事务不能读取另一个事务未提交的数据外，还保证了避免不可重复读。 ISOLATION_SERIALIZABLE 这是花费最高代价但是最可靠的事务隔离级别。事务被处理为顺序执行。除了防止脏读，不可重复读外，还避免了幻读。 关键词： 1、幻读：事务1读取记录时事务2增加了记录并提交，事务1再次读取时可以看到事务2新增的记录； 2、不可重复读：事务1读取记录时，事务2更新了记录并提交，事务1再次读取时可以看到事务2修改后的记录； 3、脏读：事务1更新了记录，但没有提交，事务2读取了更新后的行，然后事务T1回滚，现在T2读取无效。 6、Spring中BeanFactory和FactoryBean有什么区别？BeanFactory，以Factory结尾，表示它是一个工厂类(接口)，用于管理Bean的一个工厂。在Spring中，BeanFactory是IOC容器的核心接口，它的职责包括：实例化、定位、配置应用程序中的对象及建立这些对象间的依赖。 FactoryBean以Bean结尾，表示它是一个Bean，不同于普通Bean的是：它是实现了FactoryBean接口的Bean，根据该Bean的ID从BeanFactory中获取的实际上是FactoryBean的getObject()返回的对象，而不是FactoryBean本身，如果要获取FactoryBean对象，请在id前面加一个&amp;符号来获取。 7、Spring框架中IOC的原理是什么？Spring框架IOC和AOP的实现原理 8、spring的依赖注入有哪几种方式在Spring容器中为一个bean配置依赖注入有四种方式： 使用属性的setter方法注入 这是最常用的方式； 使用构造器注入； 使用Filed注入（用于注解方式）. 静态、实例工厂的方法注入 9、struts工作流程Struts2是一个基于MVC设计模式的Web应用框架，它本质上相当于一个servlet，在MVC设计模式中，Struts2作为控制器(Controller)来建立模型与视图的数据交互 Struts2=struts1+webwork。 ] struts2的执行流程： 1、客户端浏览器发出HTTP请求。 2、根据web.xml配置，该请求被FilterDispatcher接收。 3、根据struts.xml配置，找到需要调用的Action类和方法， 并通过IoC方式，将值注入给Aciton。 4、Action调用业务逻辑组件处理业务逻辑，这一步包含表单验证。 5、Action执行完毕，根据struts.xml中的配置找到对应的返回结果result，并跳转到相应页面。 6、返回HTTP响应到客户端浏览器。 10、用Spring如何实现一个切面？Spring AOP中pointcut expression表达式解析1234567891011121314151617181920@Aspect@Componentpublic class LockAspect &#123; @Pointcut(\"@annotation(xx.xx)\") public void pointcut() &#123; &#125; @Around(\"pointcut()\") public Object arount(ProceedingJoinPoint point) throws Throwable &#123; ... try &#123; return point.proceed(); &#125; catch (Exception e) &#123; throw e; &#125; finally &#123; ... &#125; &#125;&#125; 11、Spring 如何实现数据库事务？使用@Transactional注解或在配置文件里面配置 12、Hibernate对一二级缓存的使用，Lazy-Load的理解；一级缓存： hibernate的一级缓存是由session提供的，因此它只存在session的生命周期中。也就是说session关闭的时候该session所管理的一级缓存也随之被清除。hibernate的一级缓存是session所内置的，默认开启，不能被卸载，也不能进行任何配置。在缓存中的对象,具有持久性,session对象负责管理.一级缓存的优点是使用同一个session对象多次查询同一个数据对象,仅对数据库查询一次。一级缓存采用的是Key-Value的MAP方式来实现的。在缓存实体对象时，对象的主关键字ID是MAP的Key，实体对象就是对象的值。所以说一级缓存是以实体对象为单位进行存储的。访问的时候使用的是主键关键字ID。一级缓存使用的是自动维护的功能。但可以通过session提供的手动方法对一级缓存的管理进行手动干预。evict()方法用于将某个对象从session的一级缓存中清除。clear()方法用于将session缓存中的方法全部清除。 二级缓存： 二级缓存的实现原理与一级缓存是一样的。也是通过Key-Value的Map来实现对对象的缓存。二级缓存是作用在SessionFactory范围内的。因此它可被所有的Session对象所共享。需要注意的是放入缓存中的数据不能有第三方的应用对数据进行修改。 二级缓存默认关闭，需要程序员手动开启，默认为ehcache实现 get和load get: 及时加载，只要调用get方法立刻向数据库查询 load:默认使用懒加载，当用到数据的时候才向数据库查询 懒加载 当用到数据的时候才向数据库查询，这就是hibernate的懒加载特性。 延迟加载策略能避免加载应用程序不需要访问的关联对象，以提高应用程序的性能。 13、mybatis如何实现批量提交？通过标签，如 123456789101112insert into sys_user_role(`user_id`,`role_id`)values&lt;foreach collection=\"roleIdList\" item=\"item\" index=\"index\" separator=\",\"&gt; ( #&#123;userId&#125;, #&#123;item&#125; )&lt;/foreach&gt; 通过ExecutorType.BATCH，代码大致如下 12345678910111213141516public void batchInsert(List&lt;T&gt; list, Class&lt;? extends SqlMapper&lt;T&gt;&gt; mapper) &#123; sessionTemplate = new SqlSessionTemplate(sqlSessionFactory,ExecutorType.BATCH); SqlSession session = sqlSessionFactory.openSession(ExecutorType.BATCH,false); try &#123; for (T vo : list) &#123; sessionTemplate.getMapper(mapper).insert(vo); &#125; session.commit(); &#125; catch (Exception e) &#123; session.rollback(); &#125; finally &#123; session.close(); &#125;&#125; 七、数据库相关1、MySQL InnoDB、Mysaim的特点？InnoDB： 支持事务处理 支持外键 支持行锁 不支持FULLTEXT类型的索引（在Mysql5.6已引入） 不保存表的具体行数，扫描表来计算有多少行 对于AUTO_INCREMENT类型的字段，不能与其他字段建立组合索引 DELETE 表时，是一行一行的删除 InnoDB 把数据和索引存放在表空间里面 跨平台可直接拷贝使用 表格很难被压缩 MyISAM： 不支持事务，回滚将造成不完全回滚，不具有原子性 不支持外键 支持全文搜索 保存表的具体行数,不带where时，直接返回保存的行数 DELETE 表时，先drop表，然后重建表 MyISAM 表被存放在三个文件 。frm 文件存放表格定义。 数据文件是MYD (MYData) 。 索引文件是MYI (MYIndex)引伸 跨平台很难直接拷贝 AUTO_INCREMENT类型字段可以和其他字段一起建立联合索引 表格可以被压缩 选择： 因为MyISAM相对简单所以在效率上要优于InnoDB.如果系统读多，写少。对原子性要求低。那么MyISAM最好的选择。且MyISAM恢复速度快。可直接用备份覆盖恢复。如果系统读少，写多的时候，尤其是并发写入高的时候。InnoDB就是首选了。两种类型都有自己优缺点，选择那个完全要看自己的实际类弄。 2、行锁，表锁；乐观锁，悲观锁行锁：数据库表中某一行被锁住。 表锁：整个数据库表被锁住。 乐观锁：顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，具体实现是给表增加一个版本号的字段，在执行update操作时比较该版本号是否与当前数据库中版本号一致，如一致，更新数据，反之拒绝。 悲观锁：顾名思义，就是很悲观，每次去拿数据的时候都认为别人会修改。读数据的时候会上锁，直到update完成才释放锁，使用悲观锁要注意不要锁住整个表。 3、数据库隔离级别是什么？有什么作用？ISOLATION_READ_UNCOMMITTED 这是事务最低的隔离级别，它允许另外一个事务可以看到这个事务未提交的数据。这种隔离级别会产生脏读，不可重复读和幻读。 ISOLATION_READ_COMMITTED 保证一个事务修改的数据提交后才能被另外一个事务读取。另外一个事务不能读取该事务未提交的数据。这种事务隔离级别可以避免脏读出现，但是可能会出现不可重复读和幻读。 ISOLATION_REPEATABLE_READ 这种事务隔离级别可以防止脏读，不可重复读。但是可能出现幻读。它除了保证一个事务不能读取另一个事务未提交的数据外，还保证了避免不可重复读。 ISOLATION_SERIALIZABLE 这是花费最高代价但是最可靠的事务隔离级别。事务被处理为顺序执行。除了防止脏读，不可重复读外，还避免了幻读。 4、MySQL主备同步的基本原理。mysql主备复制实现分成三个步骤： 1、master将改变记录到二进制日志(binary log)中（这些记录叫做二进制日志事件，binary log events，可以通过show binlog events进行查看）； 2、slave将master的binary log events拷贝到它的中继日志(relay log)； 3、slave重做中继日志中的事件，将改变反映它自己的数据。 5、select * from table t where size &gt; 10 group by size order by size的sql语句执行顺序？sql语句执行顺序如下： where -&gt; group by -&gt; having -&gt; select -&gt; order by 6、如何优化数据库性能（索引、分库分表、批量操作、分页算法、升级硬盘SSD、业务优化、主从部署）1、选择合适的数据库引擎，使用索引 2、分页获取数据，只获取需要的字段 3、优化业务逻辑，减少数据库IO 4、分库分表 5、部署主从数据库 6、升级硬件 7、SQL什么情况下不会使用索引（不包含，不等于，函数）sql中索引不会被用到的几种情况 8、一般在什么字段上建索引（过滤数据最多的字段）1、表的主键、外键必须有索引； 2、数据量超过300的表应该有索引； 3、经常与其他表进行连接的表，在连接字段上应该建立索引； 4、经常出现在Where子句中的字段，特别是大表的字段，应该建立索引； 5、索引应该建在选择性高的字段上； 6、索引应该建在小字段上，对于大的文本字段甚至超长字段，不要建索引； 9、如何从一张表中查出name字段不包含“XYZ”的所有行？select * from table where name not like ‘%XYZ%’; 10、Redis，RDB和AOF，如何做高可用、集群redis的持久化方式RDB和AOF的区别 部署高可用的Redis集群架构 11、如何解决高并发减库存问题异步处理，减库存加锁 12、mysql存储引擎中索引的实现机制；mysql索引的实现原理 13、数据库事务的几种粒度；这个问题应该是跟数据库锁有关 数据库锁按照锁定的对象不同可分为： 表锁定：对整个表的锁定。 行锁定：只锁定进行更改的行，例如：insert，update，delete，都隐式采用行锁定。 数据库锁机制可分为多种粒度的： 数据库，表，页面，行 粒度越大，DBMS管理越容易，但是实现并发处理的能力就越差，表，页面，行 八、网络协议和网络编程1、TCP建立连接的过程。三次握手： 第一次握手：客户端发送syn包到服务器端，进入syn_send状态，等待服务器端的确认； 第二次握手：服务器端收到客户端的syn包，发送syn+ack包给客户端，进入syn_recv状态； 第三次握手：客户端收到服务器端的syn+ack包，发送个ack包到服务器端，至此，客户端与服务器端进入established状态； 握手过程中传送的包不包含任何数据，连接建立后才会开始传送数据，理想状态下，TCP连接一旦建立，在通信双方的任何一方主动关闭连接前，TCP连接都会一直保持下去。 2、TCP断开连接的过程。四次挥手： 第一次挥手：主动关闭方发送fin包到被动关闭方，告诉被动关闭方我不会再给你发送数据了； 第二次挥手：被动关闭方收到syn包，发送ack给对方，确认序号为收到序号+1； 第三次挥手：被动关闭方也也发送fin包给主动关闭方，告诉对方我也不会给你发送数据了； 第四次挥手：主动关闭方收到syn包，发送ack给对方，至此，完成四次挥手； 3、浏览器发生302跳转背后的逻辑？浏览器在原请求地址的响应的Location域找到要跳转的URI执行跳转。 浏览器输入URL后发生了什么 1.DNS域名解析；2.建立TCP连接；3.发送HTTP请求；4.服务器处理请求；5.返回响应结果；6.关闭TCP连接；7.浏览器解析HTML；8.浏览器布局渲染； 4、HTTP协议的交互流程。HTTP和HTTPS的差异，SSL的交互流程？Http协议 1、建立TCP连接； 2、发送HTTP请求； 3、服务器处理请求； 4、返回响应结果； 5、关闭TCP连接； HTTPS协议 HTTPS协议就是基于SSL的HTTP协议 HTTPS使用与HTTP不同的端口（HTTP:80 ， HTTPS:443） 提供了身份验证与加密通信方法，被广泛用于互联网上安全敏感的通信。 交互过程 客户端在使用HTTPS方式与Web服务器通信时有以下几个步骤 1、客户端请求SSL连接，并将自己支持的加密规则发给网站。 2、服务器端将自己的身份信息以证书形式发回给客户端。证书里面包含了网站地址，加密公钥，以及证书的颁发机构。 3、获得证书后，客户要做以下工作 验证证书合法性 如果证书受信任，客户端会生成一串随机数的密码，并用证书提供的公钥进行加密。 将加密好的随机数发给服务器。 4、获得到客户端发的加密了的随机数之后，服务器用自己的私钥进行解密，得到这个随机数，把这个随机数作为对称加密的密钥。 5、之后服务器与客户之间就可以用随机数对各自的信息进行加密，解密。 注意的是：证书是一个公钥，这个公钥是进行加密用的。而私钥是进行解密用的。公钥任何都知道，私钥只有自己知道。这是非对称加密。 而对称加密就是钥匙只有一把，我们都知道。之所以用到对称加密，是因为对称加密的速度更快。而非对称加密的可靠性更高。 HTTP与HTTPS的区别 1、HTTPS协议需要申请证书。 2、HTTP是明文传输；HTTPS使用的是具有安全性的SSL加密传输协议 3、HTTP端口是80；HTTPS端口号是443 4、HTTP连接简单无状态；HTTPS由SSL+HTTP协议构件的可进行加密传输、身份验证的网络协议。 5、Rest和Http什么关系？ 大家都说Rest很轻量，你对Rest风格如何理解？Http是一种协议，Rest是一种软件架构风格。 URL定位资源，用HTTP动词（GET,POST,DELETE,DETC）描述操作。 GET表示查询、POST表示新建、PUT表示更新、DELETE表示删除等。 GET /api/v1/user 获取用户列表 GET /api/v1/user/1 获取ID为1的用户 POST /api/v1/user 新建用户 PUT /api/v1/user/1 更新ID为1的用户信息 DELETE /api/v1/user/1 删除ID为1的用户 6、TCP的滑动窗口协议有什么用？讲讲原理。滑动窗口协议是传输层进行流控的一种措施，接收方通过通告发送方自己的窗口大小，从而控制发送方的发送速度，从而达到防止发送方发送速度过快而导致来不及接受。 TCP原理 滑动窗口 7、HTTP协议都有哪些方法？GET 请求获取由Request-URI所标识的资源。 POST 在Request-URI所标识的资源后附加新的数据。 HEAD 请求获取由Request-URI所标识的资源的响应消息报头。 OPTIONS 请求查询服务器的性能，或查询与资源相关的选项和需求。 PUT 请求服务器存储一个资源，并用Request-URI作为其标识。 DELETE 请求服务器删除由Request-URI所标识的资源。 TRACE 请求服务器回送收到的请求信息，主要用语测试或诊断。 8、交换机和路由器的区别？路由器与交换机的区别 1、工作层次不同 最初的交换机工作在OSI模型中的数据链路层，工作原理简单 路由器工作在OSI模型中的网络层，得更多协议信息，做更智能的转发决策 2、数据转发所依据的对象不同 交换机是利用物理地址（MAC地址），确定转发的目的地址。（MAC固化硬件，一般不可更改） 路由器是利用IP地址，确定转发的目的地址。（IP通常为网关或系统自动分配的） 3、是否可以分割广播域 传统的交换机可以分割冲突域，不能分割广播域，而路由器可以分割广播域 由交换机连接的网段仍然属于同一广播域，广播数据报会在交换机连接的所有网段上传播，某些情况导致通信拥挤和安全漏洞。连接到路由器上的网段被分配成不同的广播域，所以，广播数据不穿过路由器虽然三层交换机可以分割广播域，但是子广播域之间不能通信，还是需要路由器 4、路由器提供了防火墙的服务 路由器仅仅转发特定地址的数据包，不传送不支持路由协议的数据包，不传送未知目标网络数据包，从而可以防止广播风暴 5、表 二层交换机上存在MAC表，三层交换机上存在路由表、MAC表、ARP表，路由器上存在路由表和ARP表。 总之，交换机在具体的城域网中扮演着VLAN透传的角色，就是桥。路由器的每一个端口都是一个独立的广播域和冲突域，而交换机是只有一个广播域和端口数量的冲突域。 9、Socket交互的基本流程？socket通信基本流程 10、http协议（报文结构，断点续传，多线程下载，什么是长连接）11、tcp协议（建连过程，慢启动，滑动窗口，七层模型）12、webservice协议（wsdl/soap格式，与rest的区别）webservice、RESTful、REST通俗理解 13、NIO的好处，Netty线程模型，什么是零拷贝九、Redis等缓存系统/中间件/NoSQL/一致性Hash等1、列举一个常用的Redis客户端的并发模型。12345678910lock = 0;while (timeout &gt; 0) &#123; if (setnxexpire(key, value)) &#123; lock = 1; return lock; &#125; timeout -= sleeptime sleep(sleeptime);&#125; 2、HBase如何实现模糊查询？1234567891011121314151617181920try &#123; HTable table = new HTable(conf, tablename); Scan s = new Scan(); //查询rowkey包括xx的行 Filter filter = new RowFilter(CompareFilter.CompareOp.EQUAL, new SubstringComparator(\"xx\")); s.setFilter(filter); ResultScanner rs = table.getScanner(s); for (Result r : rs) &#123; KeyValue[] kv = r.raw(); for (int i = 0; i &lt; kv.length; i++) &#123; System.out.print(new String(kv[i].getRow()) + \" \"); System.out.print(new String(kv[i].getFamily()) + \":\"); System.out.print(new String(kv[i].getQualifier()) + \" \"); System.out.print(kv[i].getTimestamp() + \" \"); System.out.println(new String(kv[i].getValue())); &#125; &#125; &#125; catch (IOException e) &#123;&#125; 3、列举一个常用的消息中间件，如果消息要保序如何实现？ActiveMQ、RabbitMQ、kafka 实现队列，先进先出 4、如何实现一个Hashtable？你的设计如何考虑Hash冲突？如何优化？使用哈希表 Hash算法解决冲突的方法 处理散列冲突：开放定址法 开放定址法、再哈希法、链地址法、建立公共溢出区 参考Hashmap的链地址法，链表长度大于8时转为红黑树 5、分布式缓存，一致性hash分布式缓存的一致性Hash算法 （1）先构造一个长度为0~2^32的整数环，根据节点名称的Hash值，将缓存服务器节点放置在这个Hash环上。 （2）根据需要缓存的数据的KEY值计算得到其Hash值，然后在Hash环上顺时针查找距离这个KEY值的Hash值最近的缓存服务器节点，完成KEY到服务器的Hash映射查找。 补充： 这个一致性Hash环使用二叉查找树实现，Hash查找过程实际上是在二叉查找树中查找不小于查找树的最小数值。 另外，为了解决上述算法带来的负载不均衡问题，通过使用虚拟层，将每台物理缓存服务器虚拟为一组虚拟缓存服务器，将虚拟服务器的Hash值放置在Hash环上，KEY在环上先找到虚拟服务器节点，再得到物理服务器的信息。 6、LRU算法，slab分配，如何减少内存碎片两种常见的缓存淘汰算法LFU&amp;LRU 内存碎片和memcached slab控制碎片方法 7、如何解决缓存单机热点问题如何解决高并发下缓存被击穿的问题 8、什么是布隆过滤器，其实现原理是？ False positive指的是？Bloom Filter概念和原理 Bloom Filter是一种空间效率很高的随机数据结构，它利用位数组很简洁地表示一个集合，并能判断一个元素是否属于这个集合。Bloom Filter的这种高效是有一定代价的：在判断一个元素是否属于某个集合时，有可能会把不属于这个集合的元素误认为属于这个集合（false positive）。因此，Bloom Filter不适合那些“零错误”的应用场合。而在能容忍低错误率的应用场合下，Bloom Filter通过极少的错误换取了存储空间的极大节省。 9、memcache与redis的区别Redis和Memcache的区别分析 10、zookeeper有什么功能，选举算法如何进行zookeeper是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。 【分布式】Zookeeper的Leader选举 11、map/reduce过程，如何用map/reduce实现两个数据源的联合统计Hadoop Map/Reduce教程 十、设计模式与重构1、你能举例几个常见的设计模式单例模式、工厂模式、代理模式、模板方法模式 2、你在设计一个工厂的包的时候会遵循哪些原则？设计模式的六大原则 1、开闭原则（Open Close Principle） 开闭原则就是说对扩展开放，对修改关闭。在程序需要进行拓展的时候，不能去修改原有的代码，实现一个热插拔的效果。所以一句话概括就是：为了使程序的扩展性好，易于维护和升级。想要达到这样的效果，我们需要使用接口和抽象类，后面的具体设计中我们会提到这点。 2、里氏代换原则（Liskov Substitution Principle） 里氏代换原则(Liskov Substitution Principle LSP)面向对象设计的基本原则之一。 里氏代换原则中说，任何基类可以出现的地方，子类一定可以出现。 LSP是继承复用的基石，只有当衍生类可以替换掉基类，软件单位的功能不受到影响时，基类才能真正被复用，而衍生类也能够在基类的基础上增加新的行为。里氏代换原则是对“开-闭”原则的补充。实现“开-闭”原则的关键步骤就是抽象化。而基类与子类的继承关系就是抽象化的具体实现，所以里氏代换原则是对实现抽象化的具体步骤的规范。—— From Baidu 百科 3、依赖倒转原则（Dependence Inversion Principle） 这个是开闭原则的基础，具体内容：面对接口编程，依赖于抽象而不依赖于具体。 4、接口隔离原则（Interface Segregation Principle） 这个原则的意思是：使用多个隔离的接口，比使用单个接口要好。还是一个降低类之间的耦合度的意思，从这儿我们看出，其实设计模式就是一个软件的设计思想，从大型软件架构出发，为了升级和维护方便。所以上文中多次出现：降低依赖，降低耦合。 5、迪米特法则（最少知道原则）（Demeter Principle） 为什么叫最少知道原则，就是说：一个实体应当尽量少的与其他实体之间发生相互作用，使得系统功能模块相对独立。 6、合成复用原则（Composite Reuse Principle） 原则是尽量使用合成/聚合的方式，而不是使用继承 3、你能列举一个使用了Visitor/Decorator模式的开源项目/库吗？4、你在编码时最常用的设计模式有哪些？在什么场景下用？单例模式：工程中只需要类的一个实例。 工厂模式：大量的对象需要创建，并且具有相同的接口时。 5、如何实现一个单例？123456789101112131415161718192021222324public class Singleton &#123; private Singleton() &#123;&#125; private static final Singleton instance = new Singleton(); //饿汉式 public static Singleton getInstance() &#123; return instance; &#125;&#125;public class Singleton &#123; private Singleton() &#123;&#125; private static Singleton instance; //懒汉式 public static Singleton getInstance() &#123; if (instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125;&#125; 6、代理模式（动态代理）123456789101112131415161718192021222324252627public class DynamicProxyHandler implements InvocationHandler &#123; private Object tar; //绑定委托对象，并返回代理类 public Object bind(Object tar) &#123; this.tar = tar; //绑定该类实现的所有接口，取得代理类 return Proxy.newProxyInstance(tar.getClass().getClassLoader(), tar.getClass().getInterfaces(), this); &#125; public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; before(); Object result = method.invoke(tar, args); after(); return result; &#125; private void after() &#123; &#125; private void before() &#123; &#125;&#125; 7、单例模式（懒汉模式，并发初始化如何解决，volatile与lock的使用）123456789101112131415161718public class Singleton &#123; private Singleton() &#123;&#125; private static volatile Singleton instance; //懒汉式 线程安全 public static Singleton getInstance() &#123; if (instance == null) &#123; synchronize (Singleton.class) &#123; if (instance == null) &#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125;&#125; 8、JDK源码里面都有些什么让你印象深刻的设计模式使用，举例看看？【设计模式】JDK源码中用到的设计模式 迭代器模式：集合的遍历 工厂模式：java.util.Calendar#getInstance() 适配器模式：java.util.Arrays#asList() 9、设计模式UML类图与设计模式实现java设计模式–UML类图 Java开发中的23种设计模式详解","tags":[{"name":"Java","slug":"Java","permalink":"http://blog.yk95.top/tags/Java/"}]},{"title":"Java实现Redis、Zookeeper分布式锁","date":"2018-01-11T16:00:00.000Z","path":"2018/01/12/Java实现Redis、Zookeeper分布式锁/","text":"在单机环境下，使用volatile、synchronized关键字或者Jdk的各种并发API可以实现线程安全，但是这些在分布式环境下是无法保证线程安全的，所以在分布式环境下需要使用到分布式锁，分布式锁的实现目前有多种方案，可以使用数据库悲观、乐观锁，Redis、Memcached、Zookeeper分布式锁，下面分享Redis、Zookeeper分布式锁的实现代码。 1、Reids分布式锁123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159public class RedisLock implements Lock &#123; private final Logger logger = LoggerFactory.getLogger(getClass()); private ShardedJedisPool shardedJedisPool; /** * 锁ID */ private final String lockId; /** * 锁命名空间 */ private final String lockNameSpace; /** * 锁key值 */ private final String lockKey; /** * 锁超时时间，防止线程在入锁以后，无限的执行等待，默认30秒 */ private static final long EXPIRE_SECS = 30; /** * 随机等待时间最小值 */ private static final int MIN_RANDOM_SECS = 10; /** * 随机等待时间最大值 */ private static final int MAX_RANDOM_SECS = 300; /** * 是否持有锁 */ private volatile boolean locked = false; public RedisLock(ShardedJedisPool shardedJedisPool, String lockNameSpace, String lockKey) &#123; this.lockId = UUID.randomUUID().toString(); this.shardedJedisPool = shardedJedisPool; this.lockNameSpace = lockNameSpace + \":\"; this.lockKey = lockKey; &#125; @Override public void lock() &#123; if (this.tryLock()) &#123; return; &#125; throw new RuntimeException(\"未能拿到锁\"); &#125; @Override public void lockInterruptibly() throws InterruptedException &#123; this.lock(); &#125; @Override public boolean tryLock() &#123; String lock = lockNameSpace + lockKey; if (setNxAndExpire(lock, lockId, EXPIRE_SECS)) &#123; // 获得锁 locked = true; &#125; return locked; &#125; /** * Redis分布式锁 * 实现思路： * 使用了redis的set nx expire命令，缓存锁 * 执行过程： * 通过setNx尝试设置某个key的值，成功（当前没有这个锁）则返回，成功获得锁 * 失败，则等待，继续尝试获取锁，如等待超时，返回（未获得锁） * * @param time 锁等待时间 * @return * @throws InterruptedException */ @Override public boolean tryLock(long time, TimeUnit unit) throws InterruptedException &#123; String lock = lockNameSpace + lockKey; long timeout = unit.toMillis(time); while (timeout &gt;= 0) &#123; if (setNxAndExpire(lock, lockId, EXPIRE_SECS)) &#123; // 获得锁 locked = true; return locked; &#125; // 生成[10-200]区间的随机毫秒 long delayMills = generateRandomMills(MIN_RANDOM_SECS, MAX_RANDOM_SECS); timeout -= delayMills; logger.debug(\"等待锁，锁ID：&#123;&#125;，锁值：&#123;&#125;，等待时长：&#123;&#125;ms\", lockId, lock, delayMills); /* 延迟随机毫秒,防止饥饿进程的出现,即,当同时到达多个进程,只会有一个进程获得锁,其他的都用同样的频率进行尝试, 后面有来了一些进行,也以同样的频率申请锁,这将可能导致前面来的锁得不到满足. 使用随机的等待时间可以一定程度上保证公平性 */ Thread.sleep(delayMills); &#125; return locked; &#125; /** * 释放锁 */ public void unlock() &#123; if (locked) &#123; String lock = lockNameSpace + lockKey; ShardedJedis shardedJedis = shardedJedisPool.getResource(); //避免删除非自己获取得到的锁 if (lockId.equals(shardedJedis.get(lock))) &#123; shardedJedis.del(lock); &#125; shardedJedis.close(); locked = false; &#125; &#125; @Override public Condition newCondition() &#123; return null; &#125; /** * 生成[min - max]区间的随机毫秒 * * @param min * @param max * @return */ private long generateRandomMills(int min, int max) &#123; Random random = new Random(); // randNumber 将被赋值为一个 MIN 和 MAX 范围内的随机数 return random.nextInt(max - min + 1) + min; &#125; /** * setNX命令不支持expire，所以使用set命令，同时使用nx与expire * * @param key * @param value * @param expire 毫秒 * @return */ private boolean setNxAndExpire(final String key, final String value, final long expire) &#123; ShardedJedis shardedJedis = shardedJedisPool.getResource(); String result = shardedJedis.set(key, value, \"NX\", \"PX\", expire); shardedJedis.close(); return \"OK\".equals(result); &#125;&#125; 看的网上很多redis分布式实现都是使用setNx命令再expire，其实redis已经支持一个命令直接setNx并且给上expire，这个建议直接使用Jedis，Spring封装的RedisTemplate中并没有找到setNx并同时给上expire的方法 2019.01.31更新：通过RedisTemplate.execute()方法实现setNxAndExpire，具体可见源码 3、最后 2、Zookeeper分布式锁123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189public class ZookeeperLock implements Lock &#123; private final Logger logger = LoggerFactory.getLogger(getClass()); private ZooKeeper zooKeeper; //锁根节点 private final String lockNamespace; //锁值节点 private final String lockKey; //当前节点 private String currentNode; //等待的前一个节点 private String waitNode; //竞争的节点列表 private List&lt;String&gt; lockNodes; //计数器 private volatile CountDownLatch countDownLatch; /** * 是否持有锁 */ private volatile boolean locked = false; public ZookeeperLock(String address, int timeout, String lockNamespace, String lockKey) &#123; init(address, timeout); this.lockNamespace = \"/\" + lockNamespace; this.lockKey = lockKey + \"_\"; &#125; private void init(String address, int timeout) &#123; try &#123; zooKeeper = new ZooKeeper(address, timeout, watchedEvent -&gt; logger.debug(\"Zookeeper连接已建立...\") ); &#125; catch (Exception e) &#123; logger.error(e.getMessage(), e); throw new RuntimeException(e.getMessage(), e); &#125; &#125; @Override public void lock() &#123; if (this.tryLock()) &#123; return; &#125; throw new RuntimeException(\"未能拿到锁\"); &#125; @Override public void lockInterruptibly() throws InterruptedException &#123; this.lock(); &#125; @Override public boolean tryLock() &#123; String lock = lockNamespace + \"/\" + lockKey; try &#123; //确保zookeeper连接成功 ensureZookeeperConnect(); //确保根节点存在 ensureNameSpaceExist(lockNamespace); //创建临时有序节点 //节点目录为/xx/xx，节点为lockKey_xxx //currentNode值为lockKey_xxx currentNode = zooKeeper.create(lock, new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL_SEQUENTIAL).replace(lockNamespace + \"/\", \"\"); //取出所有子节点 List&lt;String&gt; childrenList = zooKeeper.getChildren(lockNamespace, false); //竞争的节点列表 lockNodes = new ArrayList&lt;&gt;(); for (String children : childrenList) &#123; if (children.startsWith(lockKey)) &#123; lockNodes.add(children); &#125; &#125; //排序 Collections.sort(lockNodes); //如当前节点为最小节点，则成功获取锁 if (currentNode.equals(lockNodes.get(0))) &#123; locked = true; &#125; return locked; &#125; catch (InterruptedException | KeeperException e) &#123; logger.error(e.getMessage(), e); throw new RuntimeException(e); &#125; &#125; /** * Zookeeper分布式锁 * 实现思路： * 使用Zookeeper最小节点的方式 * 执行过程： * 1、创建根节点，在根节点下创建顺序节点 * 2、如当前创建的节点为根节点的所有子节点中最小的，则获取锁成功； * 否则，找到当前节点的前一个节点，watch前一个节点，当前一个节点被删除时获得锁；另外，等待超时也不能获得锁 */ @Override public boolean tryLock(long time, TimeUnit unit) throws InterruptedException &#123; //等待锁 try &#123; if (tryLock()) &#123; return locked; &#125; //找到当前节点的前一个节点 waitNode = lockNodes.get(Collections.binarySearch(lockNodes, currentNode) - 1); waitLock(time, unit); return locked; &#125; catch (KeeperException e) &#123; logger.error(e.getMessage(), e); throw new RuntimeException(e); &#125; &#125; /** * 释放锁 */ @Override public void unlock() &#123; try &#123; zooKeeper.delete(lockNamespace + \"/\" + currentNode, -1); zooKeeper.close(); locked = false; &#125; catch (InterruptedException | KeeperException e) &#123; logger.error(e.getMessage(), e); &#125; &#125; @Override public Condition newCondition() &#123; return null; &#125; /** * 等待锁 */ private void waitLock(long time, TimeUnit unit) throws KeeperException, InterruptedException &#123; String waitLock = lockNamespace + \"/\" + waitNode; logger.debug(\"等待锁 &#123;&#125; 释放\", waitLock); Stat stat = zooKeeper.exists(waitLock, watchedEvent -&gt; &#123; if (countDownLatch != null) &#123; locked = true; countDownLatch.countDown(); &#125; &#125;); //前一个节点此刻存在，等待，节点消失则成功获取锁 if (stat != null) &#123; countDownLatch = new CountDownLatch(1); countDownLatch.await(time, unit); countDownLatch = null; &#125; else &#123; //前一个节点此刻不存在，获得锁 locked = true; &#125; &#125; /** * 确保根节点存在 */ private void ensureNameSpaceExist(String lockNamespace) throws KeeperException, InterruptedException &#123; Stat statS = zooKeeper.exists(lockNamespace, false); if (statS == null) &#123; //如果根节点不存在，创建 zooKeeper.create(lockNamespace, new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT); &#125; &#125; /** * 确保zookeeper连接成功，防止出现连接还未完成就执行zookeeper的get/create/exsit操作出现错误KeeperErrorCode = ConnectionLoss */ private void ensureZookeeperConnect() throws InterruptedException &#123; CountDownLatch connectedLatch = new CountDownLatch(1); zooKeeper.register(watchedEvent -&gt; &#123; if (watchedEvent.getState() == Watcher.Event.KeeperState.SyncConnected) &#123; connectedLatch.countDown(); &#125; &#125;); //zookeeper连接中则等待 if (ZooKeeper.States.CONNECTING == zooKeeper.getState()) &#123; connectedLatch.await(); &#125; &#125;&#125; 3、最后另外推荐Redis、Zookeeper分布式锁的第三方实现Redisson、Curator锁。 完整代码（包括单元测试以及Redisson、Curator锁的使用）","tags":[{"name":"Redis","slug":"Redis","permalink":"http://blog.yk95.top/tags/Redis/"},{"name":"Java","slug":"Java","permalink":"http://blog.yk95.top/tags/Java/"},{"name":"ZooKeeper","slug":"ZooKeeper","permalink":"http://blog.yk95.top/tags/ZooKeeper/"},{"name":"分布式锁","slug":"分布式锁","permalink":"http://blog.yk95.top/tags/分布式锁/"}]},{"title":"使用Hexo搭建个人Github博客","date":"2017-05-29T16:00:00.000Z","path":"2017/05/30/使用Hexo搭建个人Github博客/","text":"参考网上的文章总算把自己的Github博客搭建出来了，在这把我的搭建步骤分享给大家，后面的内容还包括了配置域名，如已搭建成功了想要使用自己的域名访问博客可以直接跳到配置域名部分。搭建个人博客-hexo+github详细完整步骤零基础免费搭建个人博客-hexo+github上面两个链接是我所参考的文章，写的也很详细，如果没看懂我的步骤也可以看看上面的。 一、准备我们需要安装Git、Node.js、Hexo以及注册一个GitHub账号。下载Git、Nodejs可以选择在官网下载，也可以去CSDN下载，大部分都是不需要积分的。PS：官网下载网速超级慢，不知道是资源问题还是墙的原因。Git官网下载地址Node.js官网下载地址Git CSDN下载Node.js CSDN下载 1、安装Git 打开Git安装程序，点击NEXT来到这个页面，选择要安装的组件，可以全选也可以默认，然后一路NEXT即可，安装路径根据自己习惯更改。 2、安装Node.js同样打开Node.js安装程序，一路默认即可，安装路径根据自己习惯更改。 3、安装Hexo安装Hexo就稍微繁琐点，不过大家一定不能急，耐心等待安装，一般来说按照步骤慢慢来都是没有问题的。首先在任意地方右键，点击“Git Bash Here”。使用NPM命令安装，为防止被墙，这里使用淘宝NPM镜像，输入命令 npm install -g cnpm --registry=https://registry.npm.taobao.org 等待安装完成。 完成后，继续输入命令 cnpm install -g hexo-cli 等待完成，再输入命令 cnpm install hexo --save 至此Hexo安装完成，使用查看版本命令 hexo -v 检查是否正常安装。 4、注册Github以及创建仓库接下来我们注册Github账号，使用常用邮箱注册即可，过程比较简单这里就不细讲了。注册成功登录后，来到我的仓库页面，点击New repository。 注意Repository name一定得是yourname.github.io，这样才能使用这个地址访问到你的Github page，填好Repository name，点击Create repository。（我这里因为之前创建过，所以报同名错误，大家第一次创建的话可以忽略）。 在零基础免费搭建个人博客-hexo+github里有个‘启用GitHub Page’的步骤，但我发现页面都已经变得不一样了，最新的页面如下所示，只需要Choose Theme就会自动启用Github Page。 创建仓库后我们后面的步骤需要用到仓库地址，进到yourname.github.io仓库页面，看下图。 二、本地启动与部署到Github1、本地启动创建一个新文件夹（我的是在E盘创建的Blog），进入该文件夹，右键Git Bash Here，输入 hexo init 命令。PS：由于博主搭建成功后并没有推倒再来一遍，所以到这里就没有截图了，大家键入命令后，在程序运行过程记得一定要耐心等待。 初始化成功后，大概是下面的目录结构（我这个是部署到git后，有多了几个文件）。 接下来输入 hexo s -g 命令启动，启动后浏览器访问localhost:4000查看博客效果。 2、部署到Github本地成功后下面就要部署到Git了，打开_config.yml进行配置，如下图，复制你的仓库地址给repo参数(上面有讲怎么复制）。 在Git命令窗口输入 npm install hexo-deployer-git --save 安装hexo-deployer-git自动部署发布工具，等待安装完成，输入 hexo clean &amp;&amp; hexo g &amp;&amp; hexo d 命令发布到Github，这里注意第一次发布的话会需要输入你的Github账号跟密码，等待出现下图的信息就说明发布成功了，在浏览器输入yourname.github.io就可以看到你的博客了。 三、选择主题与配置域名1、选择主题完成上面的步骤之后呢，可能有人会觉得默认的Hexo主题不是特别好看（至少博主是那么认为的），所以我们可以给博客选择一个适合自己的主题，使用命令 git clone https://github.com/iissnan/hexo-theme-nextthemes/[theme] 来下载一个新的主题，[theme]为主题名。下载完成后，修改_config.yml的theme参数来配置主题，见下图。 附上链接：有哪些好看的 Hexo 主题？ 博主选择的主题是yilia，这里遇到了一个坑：使用yilia主题有了两个_config.yml文件，一个是我们一直用到的，另一个是yilia主题目录下的，启用yilia的某些功能需要在我们一直用到的_config.yml文件配置，而yilia主题的定制是在yilia目录下的_config.yml配置，其他主题可能也会有这样的情况，这一点稍微注意下。 另附上yilia主题的评论配置：多说、畅言、网易云跟帖、Disqus评论配置 2、配置域名这一步骤提供给需要使用自己的域名访问Github page的读者，不需要的可以直接跳过。在cmd窗口使用 ping yourname.github.io 得到IP地址，见下图。 在你的Github博客仓库根目录下创建CNAME文件，注意不能有文件名不能有后缀且要大写，内容为你想指定的域名。 然后将你的域名映射到该IP地址，这里以博主的阿里云购买的域名举例，在阿里云域名控制台添加一条解析，如下图。 等解析生效就可以使用域名访问Github page了，例如博主的：http://yk95.top 使用域名访问Github page还需要注意一点，我们使用 hexo clean &amp;&amp; hexo g &amp;&amp; hexo d 命令将博客发布到Git时，Hexo会将整个仓库全部清空，然后才提交，这样我们创建的CNAME文件就被删除了，这里提供一个简单的解决方案，在本地博客public文件夹下创建CNAME文件，发布到Git时不clean使用 hexo g &amp;&amp; hexo d 命令，发布时会将CNAME文件一起提交。 四、发布自己的第一篇博客将博客搭建起来之后就可以开始写博客了，首先需要配置一些基本信息，这些内容不会解析到博客正文中，见下图。 接下来就是正式写博客正文了，写的文章要遵循markdown语法。附上链接：Markdown 语法说明 (简体中文版)写好博客后就可以使用命令 hexo clean &amp;&amp; hexo g &amp;&amp; hexo d 发布到Github了（域名访问的请去掉 hexo clean），下面是博客效果。 至此，本篇博客搭建教程介绍完毕，最后再附上一些链接：Hexo博客添加百度sitemapHexo插件之百度主动提交链接用阿里云的免费 SSL 证书让网站从 HTTP 换成 HTTPS","tags":[{"name":"Github","slug":"Github","permalink":"http://blog.yk95.top/tags/Github/"},{"name":"Hexo","slug":"Hexo","permalink":"http://blog.yk95.top/tags/Hexo/"},{"name":"博客","slug":"博客","permalink":"http://blog.yk95.top/tags/博客/"}]}]